{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:16.623478800Z",
     "start_time": "2024-05-08T14:57:16.455208600Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import ARGA, GCNConv, ARGVA\n",
    "from tqdm import trange\n",
    "from utils import evaluate_clustering, get_clusters, plot_training_history, plot_3d_clustering_comparison"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adversarially Regularized Graph Autoencoder\n",
    "From the paper [Adversarially Regularized Graph Autoencoder for Graph Embedding](https://arxiv.org/pdf/1802.04407)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c24cc584be8aa77b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data\n",
    "We use the Cora dataset, a standard benchmark dataset for clustering."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88f00f8c365409b2"
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = Planetoid(root='../data/Planetoid', name='Cora')\n",
    "data = dataset[0]\n",
    "data.train_mask = data.test_mask = data.val_mask = None\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:16.701701Z",
     "start_time": "2024-05-08T14:57:16.628113600Z"
    }
   },
   "id": "5d0591801dc6a541",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoder and discriminator models\n",
    "We define a simple encoder with two GCN layers for the Adversarially Regularized Graph Autoencoder. The ARGA model only uses a latent vector $z$, while the ARGVA model uses distribution parameters $\\mu$ and $\\log{\\sigma^2}$.\n",
    "The discriminator is simply a fully connected neural network with three layers."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4713098e1811a217"
  },
  {
   "cell_type": "code",
   "source": [
    "class GCNEncoder(nn.Module):\n",
    "\tdef __init__(self, in_channels, latent_dim):\n",
    "\t\tsuper(GCNEncoder, self).__init__()\n",
    "\t\tself.conv1 = GCNConv(in_channels, latent_dim)\n",
    "\t\tself.conv2 = GCNConv(latent_dim, latent_dim)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = F.relu(self.conv1(x, edge_index))\n",
    "\t\treturn self.conv2(x, edge_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:16.772903800Z",
     "start_time": "2024-05-08T14:57:16.676531Z"
    }
   },
   "id": "7039bfcb0a460529",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class VGCNEncoder(nn.Module):\n",
    "\tdef __init__(self, in_channels, latent_dim):\n",
    "\t\tsuper(VGCNEncoder, self).__init__()\n",
    "\t\tself.conv1 = GCNConv(in_channels, latent_dim)\n",
    "\t\tself.conv_mu = GCNConv(latent_dim, latent_dim)\n",
    "\t\tself.conv_logstd = GCNConv(latent_dim, latent_dim)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = F.relu(self.conv1(x, edge_index))\n",
    "\t\treturn self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:16.988822200Z",
     "start_time": "2024-05-08T14:57:16.734687200Z"
    }
   },
   "id": "2e99f8f17a65e45a",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "\tdef __init__(self, latent_dim):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(latent_dim, latent_dim)\n",
    "\t\tself.fc2 = nn.Linear(latent_dim, latent_dim)\n",
    "\t\tself.fc3 = nn.Linear(latent_dim, 1)\n",
    "\n",
    "\tdef forward(self, z):\n",
    "\t\tz = F.relu(self.fc1(z))\n",
    "\t\tz = F.relu(self.fc2(z))\n",
    "\t\treturn torch.sigmoid(self.fc3(z))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:17.046526400Z",
     "start_time": "2024-05-08T14:57:16.954690Z"
    }
   },
   "id": "5cbb7df6ca750f59",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiating and training the models\n",
    "The ARGA and ARGVA models are instantiated and trained with their built-in loss function, which uses the reconstruction loss, the regularization loss, and the KL divergence in the VGAE. The discriminator also has a built-in loss function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a49196b07a254c55"
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(model: ARGA | ARGVA, data: Data, optimizer: optim.Optimizer, discriminator_optimizer: optim.Optimizer, num_epochs: int = 200, k: int = 5, tqdm_desc: str = \"Epochs\", n_clusters: int = 7, n_tries: int = 5) -> np.ndarray:\n",
    "\tmetrics = np.zeros((num_epochs, 5))\n",
    "\tfor epoch in (pbar := trange(num_epochs, desc=tqdm_desc)):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tz = model.encode(data.x, data.edge_index)\n",
    "\t\tfor i in range(k):\n",
    "\t\t\tdiscriminator_optimizer.zero_grad()\n",
    "\t\t\tdiscriminator_loss = model.discriminator_loss(z)\n",
    "\t\t\tdiscriminator_loss.backward()\n",
    "\t\t\tdiscriminator_optimizer.step()\n",
    "\n",
    "\t\tloss = model.recon_loss(z, data.edge_index) + model.reg_loss(z)\n",
    "\t\tif isinstance(model, ARGVA):\n",
    "\t\t\t\tloss += (1 / data.num_nodes) * model.kl_loss()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\tz_np = z.detach().numpy()\n",
    "\t\tclusters = [get_clusters(z_np, n_clusters) for _ in range(n_tries)]  # the score can depend on the initial cluster assignment, so we try multiple times\n",
    "\t\taccuracy, nmi, ari, silouhette = evaluate_clustering(z_np, data.y, max(clusters, key=lambda c: evaluate_clustering(z_np, data.y, c)[0]))\n",
    "\t\tmetrics[epoch] = np.array([loss.item(), accuracy, nmi, ari, silouhette])\n",
    "\t\tpbar.set_postfix({\"Loss\": loss.item(), \"Accuracy\": accuracy, \"NMI\": nmi, \"ARI\": ari, \"Silouhette\": silouhette})\n",
    "\treturn metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:17.154518400Z",
     "start_time": "2024-05-08T14:57:17.060567300Z"
    }
   },
   "id": "fb8df9b59d594162",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "latent_dim, num_epochs, discriminator_lr, lr, n_clusters = 32, 200, .002, .001, len(np.unique(data.y.numpy()))\n",
    "\n",
    "arga_discriminator = Discriminator(latent_dim)\n",
    "arga = ARGA(GCNEncoder(data.num_features, latent_dim), arga_discriminator)\n",
    "arga_discriminator_optimizer = optim.Adam(arga_discriminator.parameters(), lr=lr)\n",
    "arga_optimizer = optim.Adam(arga.parameters(), lr=discriminator_lr)\n",
    "\n",
    "argva_discriminator = Discriminator(latent_dim)\n",
    "argva = ARGVA(VGCNEncoder(data.num_features, latent_dim), argva_discriminator)\n",
    "argva_discriminator_optimizer = optim.Adam(argva_discriminator.parameters(), lr=lr)\n",
    "argva_optimizer = optim.Adam(argva.parameters(), lr=discriminator_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:17.250899500Z",
     "start_time": "2024-05-08T14:57:17.124620Z"
    }
   },
   "id": "76f92869924dc43d",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "arga_training = train_model(arga, data, arga_optimizer, arga_discriminator_optimizer, num_epochs, tqdm_desc=\"ARGA\", n_clusters=n_clusters)\n",
    "argva_training = train_model(argva, data, argva_optimizer, argva_discriminator_optimizer, num_epochs, tqdm_desc=\"ARGVA\", n_clusters=n_clusters)\n",
    "history_labels = ['Loss', 'Accuracy', 'NMI Score', 'ARI Score', 'Silouhette Score']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:07:44.700533900Z",
     "start_time": "2024-05-08T14:57:17.216060Z"
    }
   },
   "id": "e2cad6fa65fa25c3",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_training_history(history_labels, arga_training, \"ARGA\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:07:46.074087200Z",
     "start_time": "2024-05-08T15:07:44.704850200Z"
    }
   },
   "id": "52a519fe79506303",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_training_history(history_labels, argva_training, \"ARGVA\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:07:47.532710500Z",
     "start_time": "2024-05-08T15:07:46.075085300Z"
    }
   },
   "id": "b97fe8c1a1f4d998",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "arga_z, argva_z = arga.encode(data.x, data.edge_index).detach().numpy(), argva.encode(data.x, data.edge_index).detach().numpy()\n",
    "\n",
    "n_tries = 5\n",
    "arga_clusters, argva_clusters = [get_clusters(arga_z, n_clusters) for _ in range(n_tries)], [get_clusters(argva_z, n_clusters) for _ in range(n_tries)]\n",
    "best_arga_clusters, best_argva_clusters = max(arga_clusters, key=lambda c: evaluate_clustering(arga_z, data.y, c)[0]), max(argva_clusters, key=lambda c: evaluate_clustering(argva_z, data.y, c)[0])\n",
    "\n",
    "arga_accuracy, arga_nmi, arga_ari, arga_silouhette = evaluate_clustering(arga_z, data.y, best_arga_clusters)\n",
    "argva_accuracy, argva_nmi, argva_ari, argva_silouhette = evaluate_clustering(argva_z, data.y, best_argva_clusters)\n",
    "\n",
    "print(f\"GAE Accuracy: {arga_accuracy:.4f}, NMI: {arga_nmi:.4f}, ARI: {arga_ari:.4f}, Silouhette: {arga_silouhette:.4f}\")\n",
    "print(f\"VGAE Accuracy: {argva_accuracy:.4f}, NMI: {argva_nmi:.4f}, ARI: {argva_ari:.4f}, Silouhette: {argva_silouhette:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:07:50.195074900Z",
     "start_time": "2024-05-08T15:07:47.540689100Z"
    }
   },
   "id": "d7694f47d4c6a776",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_3d_clustering_comparison(arga_z, data.y, best_arga_clusters, n_clusters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:34.220077400Z",
     "start_time": "2024-05-08T15:07:50.195074900Z"
    }
   },
   "id": "2f302064464af9f8",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_3d_clustering_comparison(argva_z, data.y, best_argva_clusters, n_clusters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:09:18.738457500Z",
     "start_time": "2024-05-08T15:08:34.220077400Z"
    }
   },
   "id": "9da14a9c96f1b884",
   "execution_count": 26,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
